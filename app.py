import streamlit as st
import pandas as pd
import io
import yaml
import bcrypt
from pathlib import Path
import streamlit.components.v1 as components
from modules.auth import get_authenticator, get_user_info
from modules.parsing import parse_uploaded_file
from modules.storage import (
    archive_raw_file,
    save_parsed_dataset,
    list_history,
    list_history_tests,
    merge_all_parsed,
    list_parsed_datasets,
    load_csv,
    delete_path,
    get_colleges,
    get_targets,
    save_targets,
    get_college_display,
)
from modules.quality import assess_qa, assess_exercises, summarize_quality

def _suggestions_for_errors(errs: dict, dtype: str) -> list[str]:
    tips = []
    if dtype == "é—®ç­”å¯¹":
        mapping = {
            "Q_EMPTY": "å¡«å†™é—®é¢˜ï¼ˆquestionï¼‰ï¼Œé¿å…ä¸ºç©º",
            "A_EMPTY": "å¡«å†™ç­”æ¡ˆï¼ˆanswerï¼‰ï¼Œé¿å…ä¸ºç©º",
            "Q_GARBLED": "ä¿®å¤é—®é¢˜ä¹±ç ï¼ˆæ£€æŸ¥ç¼–ç /éæ³•å­—ç¬¦ï¼‰",
            "A_GARBLED": "ä¿®å¤ç­”æ¡ˆä¹±ç ï¼ˆæ£€æŸ¥ç¼–ç /éæ³•å­—ç¬¦ï¼‰",
            "Q_SHORT": "é—®é¢˜é•¿åº¦å»ºè®®ä¸å°‘äº3ä¸ªå­—ç¬¦",
            "A_SHORT": "ç­”æ¡ˆé•¿åº¦è¿‡çŸ­ï¼Œè¡¥å……å®Œæ•´",
        }
    else:
        mapping = {
            "STEM_EMPTY": "è¡¥å……é¢˜å¹²ï¼ˆstemï¼‰",
            "ANS_EMPTY": "è¡¥å……ç­”æ¡ˆï¼ˆanswerï¼‰",
            "OPT_EMPTY": "è¡¥å……é€‰é¡¹ï¼ˆoptionsï¼‰ï¼Œä½¿ç”¨æ ¼å¼ï¼šA: xxx\\nB: xxx",
            "OPT_GARBLED": "ä¿®å¤é€‰é¡¹ä¹±ç ï¼ˆæ£€æŸ¥éæ³•å­—ç¬¦ä¸ç¼–ç ï¼‰",
            "ANS_NOT_IN_OPTS": "ç­”æ¡ˆéœ€ä¸ºé€‰é¡¹å­—æ¯ï¼ˆå¦‚ A/B/C/Dï¼‰ï¼Œä¸é€‰é¡¹ä¸€è‡´",
            "ANS_INVALID": "åˆ¤æ–­é¢˜ç­”æ¡ˆéœ€åœ¨ True/False/æ˜¯/å¦/å¯¹/é”™",
            "STEM_GARBLED": "ä¿®å¤é¢˜å¹²ä¹±ç ï¼ˆæ£€æŸ¥ç¼–ç ï¼‰",
            "ANS_GARBLED": "ä¿®å¤ç­”æ¡ˆä¹±ç ï¼ˆæ£€æŸ¥ç¼–ç ï¼‰",
            "KN_EMPTY": "è¡¥å……çŸ¥è¯†ç‚¹ï¼ˆknowledgeï¼‰ï¼Œå…³è”è¯¾ç¨‹ç« èŠ‚æˆ–æ¦‚å¿µ",
            "KN_GARBLED": "ä¿®å¤çŸ¥è¯†ç‚¹ä¹±ç ï¼ˆæ£€æŸ¥ç¼–ç ï¼‰",
        }
    for code in sorted(errs.keys(), key=lambda c: -errs[c]):
        tip = mapping.get(code)
        if tip:
            tips.append(f"{tip}ï¼ˆé—®é¢˜æ•°ï¼š{errs[code]}ï¼‰")
    if not tips:
        tips.append("ä¿®å¤æ‰€æœ‰æ ‡çº¢é¡¹ï¼ˆErrorï¼‰ï¼Œå¹¶é‡æ–°ä¸Šä¼ ")
    return tips
from modules.ui import render_overview, render_tabs, render_history, hide_deploy_button, render_login_branding, style_sidebar_menu

st.set_page_config(page_title="åº”ç”¨ç»æµå­¦è¯­æ–™æäº¤å¹³å°ï¼ˆæœ¬ç§‘ï¼‰", layout="wide", menu_items={"Get help": None, "Report a bug": None, "About": None})
hide_deploy_button()
render_login_branding("åº”ç”¨ç»æµå­¦è¯­æ–™æäº¤å¹³å°ï¼ˆæœ¬ç§‘ï¼‰", "è¯·ä½¿ç”¨å­¦é™¢è´¦æˆ·ç™»å½•")

authenticator = get_authenticator()
authenticator.login(
    location="main",
    fields={
        "Form name": "ç™»å½•",
        "Username": "ç”¨æˆ·å",
        "Password": "å¯†ç ",
        "Login": "ç™»å½•",
    },
)
authentication_status = st.session_state.get("authentication_status")
username = st.session_state.get("username")
name = st.session_state.get("name")

if authentication_status is False:
    st.error("ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
elif authentication_status is None:
    st.warning("è¯·è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ")
    from pathlib import Path as _P
    _gp = _P("handbook.md")
    if _gp.exists():
        _md = _gp.read_text(encoding="utf-8")
        with st.expander("åœ¨çº¿æŸ¥çœ‹ä½¿ç”¨æŒ‡å—"):
            st.markdown(_md)
    _gh = _P("handbook.html")
    if _gh.exists():
        _html = _gh.read_text(encoding="utf-8")
        components.html(_html, height=800, scrolling=True)
else:
    user_info = get_user_info(username)
    st.sidebar.success(f"å½“å‰ç”¨æˆ·ï¼š{user_info['display']}ï¼ˆ{user_info['role']}ï¼‰")
    from pathlib import Path as _P
    _gp = _P("handbook.md")
    if _gp.exists():
        _md = _gp.read_text(encoding="utf-8")
    _gh = _P("handbook.html")
    if _gh.exists():
        _html = _gh.read_text(encoding="utf-8")
        with st.sidebar.expander("åœ¨çº¿é˜…è¯»æŒ‡å— (HTML)"):
            components.html(_html, height=600, scrolling=True)
    try:
        from modules.storage import log_login
        if not st.session_state.get("login_logged"):
            log_login(username, user_info["college"])
            st.session_state["login_logged"] = True
    except Exception:
        pass
    try:
        authenticator.logout("é€€å‡ºç™»å½•", "sidebar")
    except Exception:
        pass
    if st.sidebar.button("åˆ‡æ¢è´¦å·"):
        for k in ["authentication_status", "username", "name"]:
            st.session_state.pop(k, None)
    if user_info["role"] == "admin":
        menu = ["ğŸ“Š æ±‡æ€»ç»Ÿè®¡", "ğŸ« å­¦é™¢ç®¡ç†", "ğŸ§ª æµ‹è¯•æ ·ä¾‹", "ğŸ“¦ æ±‡æ€»è¾“å‡º"]
    else:
        menu = ["â¬†ï¸ ä¸Šä¼ æ•°æ®", "ğŸ•˜ å†å²è®°å½•"]
    style_sidebar_menu()
    st.sidebar.markdown("<div class='sidebar-brand'><h2>åº”ç”¨ç»æµå­¦è¯­æ–™æäº¤å¹³å°ï¼ˆæœ¬ç§‘ï¼‰</h2><p>è¯·é€‰æ‹©èœå•</p><div class='sidebar-team'>AÂ³ T  @2025</div></div>", unsafe_allow_html=True)
    choice = st.sidebar.radio("èœå•", menu)

    if choice.endswith("ä¸Šä¼ æ•°æ®"):
        st.header("ä¸Šä¼ æ•°æ®")
        # è¿›åº¦æ¦‚è§ˆï¼ˆå«ç ”ç©¶ç”Ÿåˆ†é¡¹ï¼‰
        items = list_parsed_datasets(user_info["college"]) 
        qa_count = 0
        ex_count = 0
        ex_ug_count = 0
        ex_grad_count = 0
        for it in items:
            dfc = load_csv(it["path"])
            if it["type"] == "qa":
                qa_count += len(dfc)
            else:
                ex_count += len(dfc)
                lev = it.get("level") or (dfc.get("level").iloc[0] if "level" in dfc.columns and len(dfc) else "æœ¬ç§‘")
                if lev == "ç ”ç©¶ç”Ÿ":
                    ex_grad_count += len(dfc)
                else:
                    ex_ug_count += len(dfc)
        tgt = get_targets(user_info["college"]) 
        qa_t = int(tgt.get("qa", 0))
        ex_t = int(tgt.get("ex", 0))
        ex_ug_t = int(tgt.get("levels", {}).get("ug", {}).get("ex", 0))
        ex_grad_t = int(tgt.get("levels", {}).get("grad", {}).get("ex", 0))
        c1, c2, c3, c4 = st.columns(4)
        with c1: st.metric("é—®ç­”å¯¹æ•°é‡", qa_count)
        with c2: st.metric("é—®ç­”å¯¹ç›®æ ‡", qa_t)
        with c3: st.metric("ä¹ é¢˜æ•°é‡", ex_count)
        with c4: st.metric("ä¹ é¢˜ç›®æ ‡", ex_t)
        st.progress(0 if qa_t == 0 else min(1.0, qa_count/qa_t))
        c5, c6 = st.columns(2)
        with c5: st.metric("æœ¬ç§‘ä¹ é¢˜", f"{ex_ug_count}/{ex_ug_t}")
        with c6: st.metric("ç ”ç©¶ç”Ÿä¹ é¢˜", f"{ex_grad_count}/{ex_grad_t}")
        st.progress(0 if ex_ug_t == 0 else min(1.0, ex_ug_count/ex_ug_t))
        st.progress(0 if ex_grad_t == 0 else min(1.0, ex_grad_count/ex_grad_t))
        info = st.session_state.get("last_import_info")
        if info:
            msg = f"å·²{'å¼ºåˆ¶' if info.get('force') else ''}å…¥åº“ï¼š{info.get('type','-')}ï¼ˆ{info.get('count',0)} æ¡ï¼‰"
            if info.get('force'):
                st.warning(msg)
            else:
                st.success(msg)
            st.session_state.pop("last_import_info", None)

        st.subheader("ä¸Šä¼ å­¦é™¢æ”¶é›†çš„è¯­æ–™é›†")
        upload_type = st.radio("ä¸Šä¼ ç±»å‹", ["é—®ç­”å¯¹", "æœ¬ç§‘ä¹ é¢˜åº“", "ç ”ç©¶ç”Ÿä¹ é¢˜åº“"], horizontal=True)
        exercise_types = ["è‡ªåŠ¨è¯†åˆ«", "é€‰æ‹©é¢˜", "å¡«ç©ºé¢˜", "ç®€ç­”é¢˜", "è®ºè¿°é¢˜", "æ¡ˆä¾‹åˆ†æé¢˜", "åˆ¤æ–­é¢˜"]
        level_types = ["è‡ªåŠ¨è¯†åˆ«", "æœ¬ç§‘", "ç ”ç©¶ç”Ÿ"]
        chosen_ex_type = None
        chosen_level = None
        if upload_type == "æœ¬ç§‘ä¹ é¢˜åº“":
            # æœ¬ç§‘ä¹ é¢˜åº“ï¼šä¸æ˜¾ç¤ºçº§åˆ«é€‰æ‹©ï¼Œé»˜è®¤æœ¬ç§‘
            sel = st.selectbox("é¢˜å‹", exercise_types)
            chosen_ex_type = None if sel == "è‡ªåŠ¨è¯†åˆ«" else sel
            chosen_level = "æœ¬ç§‘"
        elif upload_type == "ç ”ç©¶ç”Ÿä¹ é¢˜åº“":
            # å¼ºåˆ¶ç ”ç©¶ç”Ÿçº§åˆ«ï¼Œä¸è¿›è¡Œçº§åˆ«è‡ªåŠ¨è¯†åˆ«
            sel = st.selectbox("é¢˜å‹", exercise_types)
            chosen_ex_type = None if sel == "è‡ªåŠ¨è¯†åˆ«" else sel
            chosen_level = "ç ”ç©¶ç”Ÿ"
        nonce = st.session_state.get("upload_nonce", 0)
        uploaded = st.file_uploader("ä¸Šä¼ å­¦é™¢æ”¶é›†çš„è¯­æ–™é›†ï¼ˆæ”¯æŒ Excel/CSVï¼‰", type=["xlsx", "xls", "csv"], key=f"main_upload_{nonce}") 
        if uploaded is not None:
            raw_path = archive_raw_file(uploaded, user_info["college"]) 
            # æœ¬ç§‘/ç ”ç©¶ç”Ÿä¹ é¢˜åº“å‡æŒ‰â€œä¹ é¢˜åº“â€è§£æï¼Œä½†å¼ºåˆ¶ä¼ å…¥ level
            _u_type = "ä¹ é¢˜åº“" if upload_type in ("æœ¬ç§‘ä¹ é¢˜åº“", "ç ”ç©¶ç”Ÿä¹ é¢˜åº“") else upload_type
            meta, df, warnings = parse_uploaded_file(uploaded, _u_type, chosen_ex_type, chosen_level)
            render_overview(meta, warnings)
            render_tabs(df, meta, key_prefix="upload_preview")
            type_mismatch = bool(meta.get("detected_type") and meta.get("type") and meta.get("detected_type") != meta.get("type"))
            if type_mismatch:
                st.error("ç±»å‹é€‰æ‹©ä¸ç³»ç»Ÿè¯†åˆ«ä¸ä¸€è‡´ï¼šè¯·æ£€æŸ¥æ–‡ä»¶ç»“æ„æˆ–æ›´æ­£ä¸Šä¼ ç±»å‹ã€‚å·²ç¦ç”¨å…¥åº“ä¸å¼ºåˆ¶å…¥åº“ã€‚")
            else:
                QUALITY_ERROR_RATIO_THRESHOLD = 0.05
                qs = (meta.get("quality_summary") or {})
                err_ratio = float(qs.get("error_row_ratio", 0.0))
                st.caption(f"è´¨é‡é”™è¯¯å æ¯”ï¼š{round(err_ratio*100,2)}%ï¼ˆé˜ˆå€¼ {int(QUALITY_ERROR_RATIO_THRESHOLD*100)}%ï¼‰")
                c1, c2 = st.columns(2)
                with c1:
                    if err_ratio <= QUALITY_ERROR_RATIO_THRESHOLD:
                        if st.button("å…¥åº“", type="primary"):
                            save_parsed_dataset(df, meta, user_info["college"]) 
                            st.session_state["last_import_info"] = {"type": meta.get('type','-'), "count": len(df), "force": False}
                            st.session_state["upload_nonce"] = nonce + 1
                            if hasattr(st, "rerun"):
                                st.rerun()
                            elif hasattr(st, "experimental_rerun"):
                                st.experimental_rerun()
                    else:
                        st.error(f"è´¨é‡é”™è¯¯å æ¯” {round(err_ratio*100,2)}% è¶…è¿‡é˜ˆå€¼ï¼Œå»ºè®®ä¿®å¤åå†å…¥åº“")
                with c2:
                    if st.button("å¼ºåˆ¶å…¥åº“ï¼ˆå¿½ç•¥è´¨é‡æ£€æµ‹ï¼‰"):
                        save_parsed_dataset(df, meta, user_info["college"]) 
                        st.session_state["last_import_info"] = {"type": meta.get('type','-'), "count": len(df), "force": True}
                        st.session_state["upload_nonce"] = nonce + 1
                        if hasattr(st, "rerun"):
                            st.rerun()
                        elif hasattr(st, "experimental_rerun"):
                            st.experimental_rerun()

    elif choice.endswith("å†å²è®°å½•"):
        st.header("å†å²è®°å½•")
        # è¿›åº¦æ¦‚è§ˆ
        items = list_parsed_datasets(user_info["college"]) 
        qa_count = 0
        ex_count = 0
        for it in items:
            dfc = load_csv(it["path"])
            if it["type"] == "qa":
                qa_count += len(dfc)
            else:
                ex_count += len(dfc)
        tgt = get_targets(user_info["college"]) 
        qa_t = int(tgt.get("qa", 0))
        ex_t = int(tgt.get("ex", 0))
        c1, c2, c3, c4 = st.columns(4)
        with c1: st.metric("é—®ç­”å¯¹æ•°é‡", qa_count)
        with c2: st.metric("é—®ç­”å¯¹ç›®æ ‡", qa_t)
        with c3: st.metric("ä¹ é¢˜æ•°é‡", ex_count)
        with c4: st.metric("ä¹ é¢˜ç›®æ ‡", ex_t)
        st.progress(0 if qa_t == 0 else min(1.0, qa_count/qa_t))
        st.progress(0 if ex_t == 0 else min(1.0, ex_count/ex_t))
        records = list_history(user_info["college"]) 
        if not records:
            st.info("æš‚æ— å†å²è®°å½•")
        else:
            summaries = []
            for it in records:
                is_qa = it["file"].endswith("_parsed_qa.csv")
                is_ex = it["file"].endswith("_parsed_ex.csv")
                if is_qa or is_ex:
                    df_tmp = load_csv(it["path"])
                    summaries.append({"ä¸Šä¼ æ—¥æœŸ": it["date"], "æ–‡ä»¶": it["file"], "ç±»å‹": ("é—®ç­”å¯¹" if is_qa else "ä¹ é¢˜åº“"), "æ¡ç›®æ•°": len(df_tmp)})
            if summaries:
                st.subheader("ä¸Šä¼ è®°å½•æ±‡æ€»")
                st.dataframe(pd.DataFrame(summaries), use_container_width=True)
            for item in records:
                is_parsed_qa = item["file"].endswith("_parsed_qa.csv")
                is_parsed_ex = item["file"].endswith("_parsed_ex.csv")
                if is_parsed_qa or is_parsed_ex:
                    df = load_csv(item["path"])
                    type_name = "é—®ç­”å¯¹" if is_parsed_qa else "ä¹ é¢˜åº“"
                    with st.expander(f"{item['date']} - {item['file']} Â· ç±»å‹ï¼š{type_name} Â· æ¡ç›®ï¼š{len(df)}"):
                        meta = {"type": type_name, "filename": item["file"], "total": len(df)}
                        render_overview(meta, [])
                        render_tabs(df, meta, key_prefix=f"history-{item['path']}")
                        if st.button("åˆ é™¤", key=f"user-del-{item['path']}"):
                            if delete_path(item["path"]):
                                st.success("å·²åˆ é™¤")
                                if hasattr(st, "rerun"):
                                    st.rerun()
                                elif hasattr(st, "experimental_rerun"):
                                    st.experimental_rerun()
                            else:
                                st.error("åˆ é™¤å¤±è´¥")
                else:
                    with st.expander(f"{item['date']} - {item['file']} Â· åŸå§‹æ–‡ä»¶"):
                        st.info("åŸå§‹æ–‡ä»¶ï¼ˆé¢„è§ˆç•¥ï¼‰")
                        with open(item["path"], "rb") as fh:
                            st.download_button("ä¸‹è½½åŸå§‹æ–‡ä»¶", fh.read(), file_name=item["file"]) 

    elif choice.endswith("æ±‡æ€»ç»Ÿè®¡"):
        st.header("æ±‡æ€»ç»Ÿè®¡")
        cols = get_colleges()
        name_map = {get_college_display(c): c for c in cols}
        st.subheader("é€‰æ‹©å­¦é™¢")
        selected_cols = []
        for disp, code in name_map.items():
            if st.checkbox(disp, value=True, key=f"stats-col-{code}"):
                selected_cols.append(code)
        level_filter = st.radio("çº§åˆ«è¿‡æ»¤", ["å…¨éƒ¨", "æœ¬ç§‘", "ç ”ç©¶ç”Ÿ"], horizontal=True)
        sort_opt = st.radio("æ’åº", ["æŒ‰é—®ç­”å¯¹æ•°é‡", "æŒ‰ä¹ é¢˜æ•°é‡", "æŒ‰è¾¾æ ‡çŠ¶æ€", "æŒ‰ç ”ç©¶ç”Ÿä¹ é¢˜æ•°é‡"], horizontal=True)
        rows = []
        for c in selected_cols:
            items = list_parsed_datasets(c)
            qa_count = 0
            ex_count = 0
            qa_frames = []
            ex_frames = []
            for it in items:
                df = load_csv(it["path"])
                if it["type"] == "qa":
                    qa_count += len(df)
                    if not df.empty:
                        qa_frames.append(df)
                else:
                    lev = it.get("level") or "æœ¬ç§‘"
                    if level_filter == "å…¨éƒ¨" or lev == level_filter:
                        ex_count += len(df)
                        if not df.empty:
                            df["level"] = lev
                            ex_frames.append(df)
            tgt = get_targets(c)
            qa_status = "è¾¾æ ‡" if qa_count >= int(tgt.get("qa", 0)) and int(tgt.get("qa", 0)) > 0 else ("æœªè®¾å®š" if int(tgt.get("qa", 0)) == 0 else "æœªè¾¾æ ‡")
            # ç»Ÿè®¡çº§åˆ«ï¼šæœ¬ç§‘ä¸ç ”ç©¶ç”Ÿ
            ex_ug_count = 0
            ex_grad_count = 0
            for it in items:
                if it["type"] == "ex":
                    df = load_csv(it["path"])
                    lev = it.get("level") or (df.get("level").iloc[0] if "level" in df.columns and len(df) else "æœ¬ç§‘")
                    if lev == "ç ”ç©¶ç”Ÿ":
                        ex_grad_count += len(df)
                    else:
                        ex_ug_count += len(df)
            ex_ug_t = int(tgt.get("levels", {}).get("ug", {}).get("ex", 0))
            ex_grad_t = int(tgt.get("levels", {}).get("grad", {}).get("ex", 0))
            ex_status = "è¾¾æ ‡" if (ex_ug_count + ex_grad_count) >= int(tgt.get("ex", 0)) and int(tgt.get("ex", 0)) > 0 else ("æœªè®¾å®š" if int(tgt.get("ex", 0)) == 0 else "æœªè¾¾æ ‡")
            ex_ug_status = "è¾¾æ ‡" if ex_ug_count >= ex_ug_t and ex_ug_t > 0 else ("æœªè®¾å®š" if ex_ug_t == 0 else "æœªè¾¾æ ‡")
            ex_grad_status = "è¾¾æ ‡" if ex_grad_count >= ex_grad_t and ex_grad_t > 0 else ("æœªè®¾å®š" if ex_grad_t == 0 else "æœªè¾¾æ ‡")
            # è´¨é‡æ±‡æ€»ï¼ˆåŠ¨æ€è¯„ä¼°ï¼Œä¸å†™å…¥æ–‡ä»¶ï¼‰
            qa_summary = {"score_avg": 0, "error_row_ratio": 0.0}
            ex_summary = {"score_avg": 0, "error_row_ratio": 0.0}
            if qa_frames:
                qa_all = pd.concat(qa_frames, ignore_index=True)
                qa_summary = summarize_quality(assess_qa(qa_all))
            if ex_frames:
                ex_all = pd.concat(ex_frames, ignore_index=True)
                ex_summary = summarize_quality(assess_exercises(ex_all))
            total_rows = (len(pd.concat(qa_frames, ignore_index=True)) if qa_frames else 0) + (len(pd.concat(ex_frames, ignore_index=True)) if ex_frames else 0)
            overall_error_ratio = 0.0
            if total_rows > 0:
                overall_error_ratio = (
                    qa_summary.get("error_row_ratio", 0.0) * (len(pd.concat(qa_frames, ignore_index=True)) if qa_frames else 0)
                    + ex_summary.get("error_row_ratio", 0.0) * (len(pd.concat(ex_frames, ignore_index=True)) if ex_frames else 0)
                ) / total_rows
            overall_score = 0.0
            if total_rows > 0:
                overall_score = (
                    qa_summary.get("score_avg", 0.0) * (len(pd.concat(qa_frames, ignore_index=True)) if qa_frames else 0)
                    + ex_summary.get("score_avg", 0.0) * (len(pd.concat(ex_frames, ignore_index=True)) if ex_frames else 0)
                ) / total_rows
            rows.append({
                "å­¦é™¢": get_college_display(c),
                "é—®ç­”å¯¹": qa_count,
                "é—®ç­”å¯¹ç›®æ ‡": int(tgt.get("qa", 0)),
                "é—®ç­”å¯¹çŠ¶æ€": qa_status,
                "ä¹ é¢˜": ex_count,
                "ä¹ é¢˜ç›®æ ‡": int(tgt.get("ex", 0)),
                "ä¹ é¢˜çŠ¶æ€": ex_status,
                "æœ¬ç§‘ä¹ é¢˜": ex_ug_count,
                "æœ¬ç§‘ç›®æ ‡": ex_ug_t,
                "æœ¬ç§‘çŠ¶æ€": ex_ug_status,
                "ç ”ç©¶ç”Ÿä¹ é¢˜": ex_grad_count,
                "ç ”ç©¶ç”Ÿç›®æ ‡": ex_grad_t,
                "ç ”ç©¶ç”ŸçŠ¶æ€": ex_grad_status,
                "è´¨é‡å‡åˆ†": round(overall_score, 2),
                "çº¢è‰²é—®é¢˜æ¯”ä¾‹": round(overall_error_ratio * 100, 2),
            })
        if rows:
            df_rows = pd.DataFrame(rows)
            if sort_opt == "æŒ‰é—®ç­”å¯¹æ•°é‡":
                df_rows = df_rows.sort_values(by=["é—®ç­”å¯¹"], ascending=False)
            elif sort_opt == "æŒ‰ä¹ é¢˜æ•°é‡":
                df_rows = df_rows.sort_values(by=["ä¹ é¢˜"], ascending=False)
            elif sort_opt == "æŒ‰ç ”ç©¶ç”Ÿä¹ é¢˜æ•°é‡":
                df_rows = df_rows.sort_values(by=["ç ”ç©¶ç”Ÿä¹ é¢˜"], ascending=False)
            else:
                status_map = {"è¾¾æ ‡": 2, "æœªè®¾å®š": 1, "æœªè¾¾æ ‡": 0}
                df_rows = df_rows.sort_values(by=["é—®ç­”å¯¹çŠ¶æ€"], key=lambda s: s.map(status_map), ascending=False)
            st.dataframe(df_rows, use_container_width=True)
            for r in rows:
                with st.expander(f"{r['å­¦é™¢']} è¯¦æƒ…"):
                    code = name_map.get(r["å­¦é™¢"], None)
                    items = list_parsed_datasets(code or r["å­¦é™¢"])  
                    # è´¨é‡ç»†èŠ‚ï¼šæŒ‰ç±»å‹æ˜¾ç¤º
                    qa_frames = []
                    ex_frames = []
                    for it in items:
                        with st.expander(f"{it['date']} - {it['file']}"):
                            df = load_csv(it["path"])
                            meta = {"type": ("é—®ç­”å¯¹" if it["type"] == "qa" else "ä¹ é¢˜åº“")}
                            render_tabs(df, meta, key_prefix=f"stats-{it['path']}")
                        if it["type"] == "qa" and not df.empty:
                            qa_frames.append(df)
                        elif it["type"] == "ex" and not df.empty:
                            df["level"] = it.get("level") or df.get("level", "æœ¬ç§‘")
                            ex_frames.append(df)
                    st.subheader("è´¨é‡æ±‡æ€»")
                    if qa_frames:
                        qa_all = pd.concat(qa_frames, ignore_index=True)
                        qa_sum = summarize_quality(assess_qa(qa_all))
                        st.write(f"é—®ç­”å¯¹ï¼šå‡åˆ† {qa_sum.get('score_avg',0)}ï¼Œçº¢è‰²é—®é¢˜æ¯”ä¾‹ {round(qa_sum.get('error_row_ratio',0)*100,2)}%")
                    if ex_frames:
                        ex_all = pd.concat(ex_frames, ignore_index=True)
                        ex_sum = summarize_quality(assess_exercises(ex_all))
                        st.write(f"ä¹ é¢˜ï¼ˆå…¨éƒ¨çº§åˆ«ï¼‰ï¼šå‡åˆ† {ex_sum.get('score_avg',0)}ï¼Œçº¢è‰²é—®é¢˜æ¯”ä¾‹ {round(ex_sum.get('error_row_ratio',0)*100,2)}%")
                        if "level" in ex_all.columns:
                            for lev, part in ex_all.groupby("level"):
                                psum = summarize_quality(assess_exercises(part))
                                st.write(f"{lev}ï¼šå‡åˆ† {psum.get('score_avg',0)}ï¼Œçº¢è‰²é—®é¢˜æ¯”ä¾‹ {round(psum.get('error_row_ratio',0)*100,2)}%")
        else:
            st.info("æš‚æ— å­¦é™¢æäº¤æ•°æ®")

    elif choice.endswith("å­¦é™¢ç®¡ç†"):
        st.header("å­¦é™¢ç®¡ç†")
        cols_codes = get_colleges()
        name_map = {code: get_college_display(code) for code in cols_codes}
        palette = {
            "economy": "#E3F2FD",
            "finance": "#FFF3E0",
            "intl": "#E8F5E9",
            "west": "#F3E5F5",
            "tax": "#FBE9E7",
            "mgmt": "#EDE7F6",
        }
        sel_code = st.session_state.get("manage_sel_code")
        if not sel_code:
            st.subheader("è¿›åº¦ç¼©ç•¥å›¾")
            cols_per_row = 3
            for i in range(0, len(cols_codes), cols_per_row):
                row = st.columns(cols_per_row)
                for j, code in enumerate(cols_codes[i:i+cols_per_row]):
                    with row[j]:
                        items = list_parsed_datasets(code)
                        qa_count = 0
                        ex_count = 0
                        ex_ug_count = 0
                        ex_grad_count = 0
                        for it in items:
                            df = load_csv(it["path"])
                            if it["type"] == "qa":
                                qa_count += len(df)
                            else:
                                ex_count += len(df)
                                lev = it.get("level") or (df.get("level").iloc[0] if "level" in df.columns and len(df) else "æœ¬ç§‘")
                                if lev == "ç ”ç©¶ç”Ÿ":
                                    ex_grad_count += len(df)
                                else:
                                    ex_ug_count += len(df)
                        tgt = get_targets(code)
                        qa_t = int(tgt.get("qa", 0))
                        ex_t = int(tgt.get("ex", 0))
                        ex_ug_t = int(tgt.get("levels", {}).get("ug", {}).get("ex", 0))
                        ex_grad_t = int(tgt.get("levels", {}).get("grad", {}).get("ex", 0))
                        qa_ratio = 0 if qa_t == 0 else min(1.0, qa_count/qa_t)
                        ex_ratio = 0 if ex_t == 0 else min(1.0, ex_count/ex_t)
                        ex_ug_ratio = 0 if ex_ug_t == 0 else min(1.0, ex_ug_count/ex_ug_t)
                        ex_grad_ratio = 0 if ex_grad_t == 0 else min(1.0, ex_grad_count/ex_grad_t)
                        bg = palette.get(code, "#F5F5F5")
                        hx = bg.lstrip('#')
                        r, g, b = int(hx[0:2], 16), int(hx[2:4], 16), int(hx[4:6], 16)
                        gradient = f"radial-gradient(circle at 50% 40%, rgba({r},{g},{b},0.12) 0%, rgba({r},{g},{b},0.22) 60%, rgba({r},{g},{b},0.32) 100%)"
                        st.markdown(
                            f"<div style='background:{gradient};padding:12px;border-radius:8px;color:#0F172A'>"
                            f"<b>{name_map[code]}</b><br/>"
                            f"é—®ç­”å¯¹ï¼š{qa_count}/{qa_t}<br/>"
                            f"æœ¬ç§‘ä¹ é¢˜ï¼š{ex_ug_count}/{ex_ug_t}<br/>"
                            f"ç ”ç©¶ç”Ÿä¹ é¢˜ï¼š{ex_grad_count}/{ex_grad_t}</div>",
                            unsafe_allow_html=True,
                        )
                        st.progress(qa_ratio)
                        st.progress(ex_ug_ratio)
                        st.progress(ex_grad_ratio)
                        if st.button("æŸ¥çœ‹è¯¦æƒ…", key=f"goto-{code}"):
                            st.session_state["manage_sel_code"] = code
            if st.button("â• æ·»åŠ å­¦é™¢", key="add_college_toggle"):
                st.session_state["show_add_form"] = not st.session_state.get("show_add_form", False)
            if st.session_state.get("show_add_form"):
                with st.form("add_college_form"):
                    new_username = st.text_input("ç”¨æˆ·å", help="ä¾‹å¦‚ user_newcollege")
                    new_name = st.text_input("å­¦é™¢åç§°")
                    new_email = st.text_input("é‚®ç®±")
                    new_password = st.text_input("åˆå§‹å¯†ç ", type="password")
                    submitted = st.form_submit_button("æ·»åŠ å­¦é™¢")
                    if submitted and new_username and new_name and new_email and new_password:
                        cfg_path = Path("config/users.yaml")
                        if cfg_path.exists():
                            with open(cfg_path, "r", encoding="utf-8") as f:
                                data = yaml.safe_load(f)
                        else:
                            data = {"credentials": {"usernames": {}}, "cookie": {"name": "auth_cookie", "key": "random_key", "expiry_days": 1}, "preauthorized": {"emails": []}}
                        hashed = bcrypt.hashpw(new_password.encode(), bcrypt.gensalt()).decode()
                        data.setdefault("credentials", {}).setdefault("usernames", {})[new_username] = {"email": new_email, "name": new_name, "password": hashed}
                        cfg_path.parent.mkdir(parents=True, exist_ok=True)
                        with open(cfg_path, "w", encoding="utf-8") as f:
                            yaml.safe_dump(data, f, allow_unicode=True)
                        st.success("å·²æ–°å¢å­¦é™¢ä¸è´¦æˆ·")
        else:
            code = sel_code
            st.subheader(f"ç›®æ ‡è®¾ç½® - {get_college_display(code)}")
            targets = get_targets(code)
            qa_t = st.number_input("é—®ç­”å¯¹ç›®æ ‡æ•°é‡", min_value=0, value=int(targets.get("qa", 0)))
            ex_ug_t = st.number_input("æœ¬ç§‘ä¹ é¢˜ç›®æ ‡æ•°é‡", min_value=0, value=int(targets.get("levels", {}).get("ug", {}).get("ex", 0)))
            ex_grad_t = st.number_input("ç ”ç©¶ç”Ÿä¹ é¢˜ç›®æ ‡æ•°é‡", min_value=0, value=int(targets.get("levels", {}).get("grad", {}).get("ex", 0)))
            st.subheader("ä¹ é¢˜é¢˜å‹ç›®æ ‡è®¾ç½®")
            type_target_names = ["é€‰æ‹©é¢˜", "å¡«ç©ºé¢˜", "ç®€ç­”é¢˜", "è®ºè¿°é¢˜", "æ¡ˆä¾‹åˆ†æé¢˜", "åˆ¤æ–­é¢˜"]
            type_target_vals = {}
            for tname in type_target_names:
                type_target_vals[tname] = st.number_input(f"{tname}ç›®æ ‡æ•°é‡", min_value=0, value=int(targets.get("types", {}).get(tname, 0)))
            if st.button("ä¿å­˜ç›®æ ‡è®¾ç½®", key="save_targets_manage"):
                save_targets(code, qa_t, ex_ug_t, ex_grad_t, types=type_target_vals)
                st.success("å·²ä¿å­˜")
            if st.button("è¿”å›å­¦é™¢ç®¡ç†", key="back_manage"):
                st.session_state.pop("manage_sel_code", None)
                if hasattr(st, "rerun"):
                    st.rerun()
                elif hasattr(st, "experimental_rerun"):
                    st.experimental_rerun()
            if st.button("ä¿å­˜ç›®æ ‡è®¾ç½®"):
                save_targets(code, qa_t, ex_t, types=type_target_vals)
                st.success("å·²ä¿å­˜")
                st.session_state.pop("manage_sel_code", None)
                if hasattr(st, "rerun"):
                    st.rerun()
                elif hasattr(st, "experimental_rerun"):
                    st.experimental_rerun()
            with st.expander("ä¸Šä¼ è®°å½•ä¸é¢„è§ˆ"):
                parsed = list_parsed_datasets(code)
                for item in parsed:
                    with st.expander(f"{item['date']} - {item['file']} ({'é—®ç­”å¯¹' if item['type']=='qa' else 'ä¹ é¢˜åº“'})"):
                        df = load_csv(item["path"])
                        meta = {"type": ("é—®ç­”å¯¹" if item["type"] == "qa" else "ä¹ é¢˜åº“")}
                        render_tabs(df, meta, key_prefix=f"manage-{item['path']}")
                        if st.button("åˆ é™¤", key=f"del-{item['path']}"):
                            if delete_path(item["path"]):
                                st.success("å·²åˆ é™¤")
                            else:
                                st.error("åˆ é™¤å¤±è´¥")
            with st.expander("è´¦æˆ·ä¸ç™»å½•ç®¡ç†"):
                with st.form("change_password_form"):
                    ch_username = st.text_input("é€‰æ‹©ç”¨æˆ·å")
                    ch_new_pwd = st.text_input("æ–°å¯†ç ", type="password")
                    ch_submit = st.form_submit_button("ä¿®æ”¹å¯†ç ")
                    if ch_submit and ch_username and ch_new_pwd:
                        cfg_path = Path("config/users.yaml")
                        if not cfg_path.exists():
                            st.error("é…ç½®ä¸å­˜åœ¨")
                        else:
                            with open(cfg_path, "r", encoding="utf-8") as f:
                                data = yaml.safe_load(f)
                            users = data.get("credentials", {}).get("usernames", {})
                            if ch_username not in users:
                                st.error("ç”¨æˆ·ä¸å­˜åœ¨")
                            else:
                                users[ch_username]["password"] = bcrypt.hashpw(ch_new_pwd.encode(), bcrypt.gensalt()).decode()
                                with open(cfg_path, "w", encoding="utf-8") as f:
                                    yaml.safe_dump(data, f, allow_unicode=True)
                                st.success("å·²ä¿®æ”¹å¯†ç ")
                from modules.storage import list_logins
                logs = list_logins(code)
                if not logs:
                    st.info("æš‚æ— ç™»å½•è®°å½•")
                else:
                    for entry in logs:
                        with st.expander(entry["date"]):
                            for e in entry["events"]:
                                st.write(e)

    elif choice.endswith("æµ‹è¯•æ ·ä¾‹"):
        st.header("æµ‹è¯•æ ·ä¾‹")
        if user_info["role"] == "admin":
            tab_sample, tab_upload, tab_history, tab_history_test = st.tabs(["ä¸Šä¼ æ ·ä¾‹", "ä¸Šä¼ æ•°æ®", "å†å²è®°å½•", "æµ‹è¯•å†å²"])
            with tab_sample:
                upload_type = st.radio("ç±»å‹", ["é—®ç­”å¯¹", "ä¹ é¢˜åº“"], horizontal=True, key="test_type")
                exercise_types = ["è‡ªåŠ¨è¯†åˆ«", "é€‰æ‹©é¢˜", "å¡«ç©ºé¢˜", "ç®€ç­”é¢˜", "è®ºè¿°é¢˜", "æ¡ˆä¾‹åˆ†æé¢˜", "åˆ¤æ–­é¢˜"]
                chosen_ex_type = None
                if upload_type == "ä¹ é¢˜åº“":
                    sel = st.selectbox("é¢˜å‹", exercise_types, key="test_ex_type")
                    chosen_ex_type = None if sel == "è‡ªåŠ¨è¯†åˆ«" else sel
                uploaded = st.file_uploader("ä¸Šä¼ æ ·ä¾‹æ–‡ä»¶", type=["xlsx", "xls", "csv"], key="test_uploader")
                if uploaded is not None:
                    meta, df, warnings = parse_uploaded_file(uploaded, upload_type, chosen_ex_type)
                    render_overview(meta, warnings)
                    render_tabs(df, meta, key_prefix="test_sample")
                    ok = True
                    if upload_type == "é—®ç­”å¯¹":
                        ok = df is not None and not df.empty and set(["question", "answer"]).issubset(set(df.columns))
                    else:
                        required = {"stem", "answer"}
                        ok = df is not None and not df.empty and required.issubset(set(df.columns))
                    st.success("æ ·ä¾‹æ»¡è¶³åŸºæœ¬è¦æ±‚") if ok else st.error("æ ·ä¾‹ä¸æ»¡è¶³åŸºæœ¬è¦æ±‚")
            with tab_upload:
                upload_type = st.radio("ç±»å‹", ["é—®ç­”å¯¹", "ä¹ é¢˜åº“"], horizontal=True, key="admin_upload_type")
                exercise_types = ["è‡ªåŠ¨è¯†åˆ«", "é€‰æ‹©é¢˜", "å¡«ç©ºé¢˜", "ç®€ç­”é¢˜", "è®ºè¿°é¢˜", "æ¡ˆä¾‹åˆ†æé¢˜", "åˆ¤æ–­é¢˜"]
                chosen_ex_type = None
                if upload_type == "ä¹ é¢˜åº“":
                    sel = st.selectbox("é¢˜å‹", exercise_types, key="admin_upload_ex_type")
                    chosen_ex_type = None if sel == "è‡ªåŠ¨è¯†åˆ«" else sel
                uploaded = st.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶", type=["xlsx", "xls", "csv"], key="admin_upload_uploader")
                if uploaded is not None:
                    raw_path = archive_raw_file(uploaded, user_info["college"]) 
                    meta, df, warnings = parse_uploaded_file(uploaded, upload_type, chosen_ex_type)
                    render_overview(meta, warnings)
                    render_tabs(df, meta, key_prefix="admin_upload_preview")
                    save_parsed_dataset(df, meta, user_info["college"]) 
            with tab_history:
                records = list_history(user_info["college"]) 
                if not records:
                    st.info("æš‚æ— å†å²è®°å½•")
                else:
                    summaries = []
                    for it in records:
                        is_qa = it["file"].endswith("_parsed_qa.csv")
                        is_ex = it["file"].endswith("_parsed_ex.csv")
                        if is_qa or is_ex:
                            df_tmp = load_csv(it["path"])
                            summaries.append({"ä¸Šä¼ æ—¥æœŸ": it["date"], "æ–‡ä»¶": it["file"], "ç±»å‹": ("é—®ç­”å¯¹" if is_qa else "ä¹ é¢˜åº“"), "æ¡ç›®æ•°": len(df_tmp)})
                    if summaries:
                        st.subheader("ä¸Šä¼ è®°å½•æ±‡æ€»")
                        st.dataframe(pd.DataFrame(summaries), use_container_width=True)
                    for item in records:
                        is_parsed_qa = item["file"].endswith("_parsed_qa.csv")
                        is_parsed_ex = item["file"].endswith("_parsed_ex.csv")
                        if is_parsed_qa or is_parsed_ex:
                            df = load_csv(item["path"])
                            type_name = "é—®ç­”å¯¹" if is_parsed_qa else "ä¹ é¢˜åº“"
                            with st.expander(f"{item['date']} - {item['file']} Â· ç±»å‹ï¼š{type_name} Â· æ¡ç›®ï¼š{len(df)}"):
                                meta = {"type": type_name, "filename": item["file"], "total": len(df)}
                                render_overview(meta, [])
                                render_tabs(df, meta, key_prefix=f"test_history-{item['path']}")
                        else:
                            with st.expander(f"{item['date']} - {item['file']} Â· åŸå§‹æ–‡ä»¶"):
                                st.info("åŸå§‹æ–‡ä»¶ï¼ˆé¢„è§ˆç•¥ï¼‰")
                                with open(item["path"], "rb") as fh:
                                    st.download_button("ä¸‹è½½åŸå§‹æ–‡ä»¶", fh.read(), file_name=item["file"]) 
            with tab_history_test:
                records = list_history_tests(user_info["college"]) 
                if not records:
                    st.info("æš‚æ— æµ‹è¯•å†å²")
                else:
                    summaries = []
                    for it in records:
                        is_qa = it["file"].endswith("_parsed_qa.csv")
                        is_ex = it["file"].endswith("_parsed_ex.csv")
                        if is_qa or is_ex:
                            df_tmp = load_csv(it["path"])
                            summaries.append({"ä¸Šä¼ æ—¥æœŸ": it["date"], "æ–‡ä»¶": it["file"], "ç±»å‹": ("é—®ç­”å¯¹" if is_qa else "ä¹ é¢˜åº“"), "æ¡ç›®æ•°": len(df_tmp)})
                    if summaries:
                        st.subheader("æµ‹è¯•è®°å½•æ±‡æ€»")
                        st.dataframe(pd.DataFrame(summaries), use_container_width=True)
                    for item in records:
                        is_parsed_qa = item["file"].endswith("_parsed_qa.csv")
                        is_parsed_ex = item["file"].endswith("_parsed_ex.csv")
                        if is_parsed_qa or is_parsed_ex:
                            df = load_csv(item["path"])
                            type_name = "é—®ç­”å¯¹" if is_parsed_qa else "ä¹ é¢˜åº“"
                            with st.expander(f"{item['date']} - {item['file']} Â· ç±»å‹ï¼š{type_name} Â· æ¡ç›®ï¼š{len(df)}"):
                                meta = {"type": type_name, "filename": item["file"], "total": len(df)}
                                render_overview(meta, [])
                                render_tabs(df, meta, key_prefix=f"test_history_test-{item['path']}")
                        else:
                            with st.expander(f"{item['date']} - {item['file']} Â· åŸå§‹æ–‡ä»¶"):
                                st.info("åŸå§‹æ–‡ä»¶ï¼ˆé¢„è§ˆç•¥ï¼‰")
                                with open(item["path"], "rb") as fh:
                                    st.download_button("ä¸‹è½½åŸå§‹æ–‡ä»¶", fh.read(), file_name=item["file"]) 
        else:
            upload_type = st.radio("ç±»å‹", ["é—®ç­”å¯¹", "ä¹ é¢˜åº“"], horizontal=True, key="test_type")
            exercise_types = ["è‡ªåŠ¨è¯†åˆ«", "é€‰æ‹©é¢˜", "å¡«ç©ºé¢˜", "ç®€ç­”é¢˜", "è®ºè¿°é¢˜", "æ¡ˆä¾‹åˆ†æé¢˜", "åˆ¤æ–­é¢˜"]
            chosen_ex_type = None
            if upload_type == "ä¹ é¢˜åº“":
                sel = st.selectbox("é¢˜å‹", exercise_types, key="test_ex_type")
                chosen_ex_type = None if sel == "è‡ªåŠ¨è¯†åˆ«" else sel
            uploaded = st.file_uploader("ä¸Šä¼ æ ·ä¾‹æ–‡ä»¶", type=["xlsx", "xls", "csv"], key="test_uploader")
            if uploaded is not None:
                meta, df, warnings = parse_uploaded_file(uploaded, upload_type, chosen_ex_type)
                render_overview(meta, warnings)
                render_tabs(df, meta, key_prefix="test_sample_non_admin")
                ok = True
                if upload_type == "é—®ç­”å¯¹":
                    ok = df is not None and not df.empty and set(["question", "answer"]).issubset(set(df.columns))
                else:
                    required = {"stem", "answer"}
                    ok = df is not None and not df.empty and required.issubset(set(df.columns))
                st.success("æ ·ä¾‹æ»¡è¶³åŸºæœ¬è¦æ±‚") if ok else st.error("æ ·ä¾‹ä¸æ»¡è¶³åŸºæœ¬è¦æ±‚")

    elif choice.endswith("æ±‡æ€»è¾“å‡º"):
        st.header("æ±‡æ€»è¾“å‡º")
        cols = get_colleges()
        name_map = {get_college_display(c): c for c in cols}
        st.subheader("é€‰æ‹©å­¦é™¢")
        select_all = st.checkbox("é€‰æ‹©æ‰€æœ‰å­¦é™¢ï¼ˆå»é™¤æ¼”ç¤ºè´¦æˆ·ï¼‰", value=True, key="export-select-all")
        selected_names = []
        for disp, code in name_map.items():
            if st.checkbox(disp, value=not select_all, key=f"export-col-{code}"):
                selected_names.append(disp)
        fmt = st.radio("æ ¼å¼", ["CSV", "Excel"], horizontal=True, key="export_fmt")
        def _to_excel(frames: dict[str, pd.DataFrame]):
            buf = io.BytesIO()
            with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
                for name, frame in frames.items():
                    frame.to_excel(writer, index=False, sheet_name=name[:31])
            buf.seek(0)
            return buf
        if select_all:
            selected_codes = [code for disp, code in name_map.items() if ("æ¼”ç¤º" not in disp) and (code != "demo")]
        else:
            selected_codes = [name_map[n] for n in selected_names] if selected_names else cols
        if len(selected_codes) == 1:
            code = selected_codes[0]
            items = list_parsed_datasets(code)
            qa_frames = []
            ex_frames = []
            for it in items:
                df = load_csv(it["path"])
                if it["type"] == "qa":
                    qa_frames.append(df)
                else:
                    ex_frames.append(df)
            qa_df = pd.concat(qa_frames, ignore_index=True) if qa_frames else pd.DataFrame()
            ex_df = pd.concat(ex_frames, ignore_index=True) if ex_frames else pd.DataFrame()
            disp = get_college_display(code)
            if fmt == "CSV":
                st.download_button("ä¸‹è½½è¯¥å­¦é™¢é—®ç­”å¯¹ (CSV)", qa_df.to_csv(index=False).encode("utf-8"), file_name=f"{disp}_qa.csv")
                st.download_button("ä¸‹è½½è¯¥å­¦é™¢ä¹ é¢˜ (CSV)", ex_df.to_csv(index=False).encode("utf-8"), file_name=f"{disp}_exercises.csv")
                if not ex_df.empty and "level" in ex_df.columns:
                    grad_df = ex_df[ex_df["level"].astype(str) == "ç ”ç©¶ç”Ÿ"]
                    st.download_button("ä¸‹è½½è¯¥å­¦é™¢ç ”ç©¶ç”Ÿä¹ é¢˜ (CSV)", grad_df.to_csv(index=False).encode("utf-8"), file_name=f"{disp}_ç ”ç©¶ç”Ÿ_ä¹ é¢˜åº“.csv")
            else:
                sheets = {"é—®ç­”å¯¹": qa_df}
                if not ex_df.empty and "type" in ex_df.columns:
                    for t, part in ex_df.groupby("type"):
                        sheets[str(t)] = part
                else:
                    sheets["ä¹ é¢˜åº“"] = ex_df
                buf = _to_excel(sheets)
                st.download_button("ä¸‹è½½è¯¥å­¦é™¢æ±‡æ€» (Excel)", buf.getvalue(), file_name=f"{disp}_æ±‡æ€».xlsx")
        else:
            all_cols = selected_codes
            qa_frames = []
            ex_frames = []
            for c in all_cols:
                items = list_parsed_datasets(c)
                for it in items:
                    df = load_csv(it["path"])
                    if it["type"] == "qa":
                        df["college"] = get_college_display(c)
                        qa_frames.append(df)
                    else:
                        df["college"] = get_college_display(c)
                        ex_frames.append(df)
            qa_all = pd.concat(qa_frames, ignore_index=True) if qa_frames else pd.DataFrame()
            ex_all = pd.concat(ex_frames, ignore_index=True) if ex_frames else pd.DataFrame()
            if fmt == "CSV":
                st.download_button("ä¸‹è½½æ‰€æœ‰å­¦é™¢é—®ç­”å¯¹ (CSV)", qa_all.to_csv(index=False).encode("utf-8"), file_name="å…¨éƒ¨_é—®ç­”å¯¹.csv")
                st.download_button("ä¸‹è½½æ‰€æœ‰å­¦é™¢ä¹ é¢˜ (CSV)", ex_all.to_csv(index=False).encode("utf-8"), file_name="å…¨éƒ¨_ä¹ é¢˜åº“.csv")
                if not ex_all.empty and "level" in ex_all.columns:
                    grad_all = ex_all[ex_all["level"].astype(str) == "ç ”ç©¶ç”Ÿ"]
                    st.download_button("ä¸‹è½½æ‰€æœ‰å­¦é™¢ç ”ç©¶ç”Ÿä¹ é¢˜ (CSV)", grad_all.to_csv(index=False).encode("utf-8"), file_name="å…¨éƒ¨_ç ”ç©¶ç”Ÿ_ä¹ é¢˜åº“.csv")
            else:
                sheets = {"é—®ç­”å¯¹": qa_all}
                if not ex_all.empty and "type" in ex_all.columns:
                    for t, part in ex_all.groupby("type"):
                        sheets[str(t)] = part
                else:
                    sheets["ä¹ é¢˜åº“"] = ex_all
                buf = _to_excel(sheets)
                st.download_button("ä¸‹è½½æ‰€æœ‰å­¦é™¢æ±‡æ€» (Excel)", buf.getvalue(), file_name="å…¨éƒ¨_æ±‡æ€».xlsx")
